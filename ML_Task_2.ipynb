{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### <center>Classsification Techniques</center>"
      ],
      "metadata": {
        "id": "Wy8cS5mY5fO5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QqxMSiooSjp"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QyNglfYoSkG"
      },
      "source": [
        "iris = pd.read_csv(\"Iris.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPuJqAiFoSkl"
      },
      "source": [
        "iris.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrsRzGv3oSk6"
      },
      "source": [
        "iris.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3Szee0QoSlK"
      },
      "source": [
        "### removing unneeded column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANFLYasaoSlP"
      },
      "source": [
        "iris.drop(\"Id\", axis=1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMpQOzUWoSlj"
      },
      "source": [
        "### Some EDA with Iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji2cuUQ2oSll"
      },
      "source": [
        "fig = iris[iris.Species == 'Iris-setosa'].plot(kind='scatter', x='SepalLengthCm', y='SepalWidthCm', color='orange', label='Setosa')\n",
        "iris[iris.Species == 'Iris-versicolor'].plot(kind='scatter', x='SepalLengthCm', y='SepalWidthCm', color='blue', label='Versicolor', ax=fig)\n",
        "iris[iris.Species == 'Iris-virginica'].plot(kind='scatter', x='SepalLengthCm', y='SepalWidthCm', color='green', label='Virginica', ax=fig)\n",
        "\n",
        "fig.set_xlabel('Sepal Length')\n",
        "fig.set_ylabel('Sepal Width')\n",
        "fig.set_title('Sepal Length Vs Width')\n",
        "\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(10, 7)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC52r4HMoSmF"
      },
      "source": [
        "fig = iris[iris.Species == 'Iris-setosa'].plot(kind='scatter', x='PetalLengthCm', y='PetalWidthCm', color='orange', label='Setosa')\n",
        "iris[iris.Species == 'Iris-versicolor'].plot(kind='scatter', x='PetalLengthCm', y='PetalWidthCm', color='blue', label='Versicolor', ax=fig)\n",
        "iris[iris.Species == 'Iris-virginica'].plot(kind='scatter', x='PetalLengthCm', y='PetalWidthCm', color='green', label='Virginica', ax=fig)\n",
        "\n",
        "fig.set_xlabel('Petal Length')\n",
        "fig.set_ylabel('Petal Width')\n",
        "fig.set_title('Petal Length Vs Width')\n",
        "\n",
        "fig=plt.gcf()\n",
        "fig.set_size_inches(10, 7)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoreCXopoSmU"
      },
      "source": [
        "iris.hist(edgecolor='black', linewidth=1.2)\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(12,6)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OTQdE1aoSm1"
      },
      "source": [
        "# importing alll the necessary packages to use the various classification algorithms\n",
        "from sklearn.model_selection import train_test_split # to split the dataset for training and testing\n",
        "from sklearn import metrics # for checking the model accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpgser0hoSnE"
      },
      "source": [
        "iris.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbA8dKSaoSnW"
      },
      "source": [
        "Now, when we train any algorithm, the number of features and their correlation plays an important role. If there are features and many of the features are highly correlated, then training an algorithm with all the featues will reduce the accuracy. Thus features selection should be done carefully. This dataset has less featues but still we will see the correlation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTNFZB9voSnY"
      },
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "sns.heatmap(iris.corr(), annot=True, cmap='cubehelix_r') # draws heatmap with input as correlation matrix calculated by iris.corr()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GlxjXStoSnl"
      },
      "source": [
        "Observation--->\n",
        "The Sepal Width and Length are not correlated The Petal Width and Length are highly correlated\n",
        "We will use all the features for training the algorithm and check the accuracy.\n",
        "\n",
        "Then we will use 1 Petal Feature and 1 Sepal Feature to check the accuracy of the algorithm as we are using only 2 features that are not correlated. Thus we can have a variance in the dataset which may help in better accuracy. We will check it later.\n",
        "\n",
        "Steps To Be followed When Applying an Algorithm\n",
        "\n",
        "Split the dataset into training and testing dataset. The testing dataset is generally smaller than training one as it will help in training the model better.\n",
        "\n",
        "Select any algorithm based on the problem (classification or regression) whatever you feel may be good.\n",
        "Then pass the training dataset to the algorithm to train it. We use the .fit() method\n",
        "Then pass the testing data to the trained algorithm to predict the outcome. We use the .predict() method.\n",
        "We then check the accuracy by passing the predicted outcome and the actual output to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9bRb2DhoSnn"
      },
      "source": [
        "## Splitting The Data into Training And Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEDGsbQzoSnq"
      },
      "source": [
        "train, test = train_test_split(iris, test_size=0.3) # our main data split into train and test\n",
        "# the attribute test_size=0.3 splits the data into 70% and 30% ratio. train=70% and test=30%\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "831aDhFXoSn9"
      },
      "source": [
        "train_X = train[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']] # taking the training data features\n",
        "train_y = train.Species # output of the training data\n",
        "\n",
        "test_X = test[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']] # taking test data feature\n",
        "test_y = test.Species # output value of the test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydQVfCLwoSoJ"
      },
      "source": [
        "train_X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQVtyzvuoSoX"
      },
      "source": [
        "test_X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaYdHc6zoSoi"
      },
      "source": [
        "train_y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression # for Logistic Regression Algorithm\n",
        "model1 = LogisticRegression(random_state=0, max_iter=1000)\n",
        "\n",
        "# we train the algorithm with training data and training output\n",
        "model1.fit(train_X, train_y)\n",
        "\n",
        "# we pass the testing data to the stored algorithm to predict the outcome\n",
        "prediction1 = model1.predict(test_X)\n",
        "print('The accuracy of the Logistic Regression is: ', metrics.accuracy_score(prediction1, test_y)) # we check the accuracy of the algorithm\n",
        "#we pass the predicted output by the model and the actual output"
      ],
      "metadata": {
        "id": "_VYcbtztz-59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier # for using DTA\n",
        "model2 = DecisionTreeClassifier()\n",
        "\n",
        "# we train the algorithm with training data and training output\n",
        "model2.fit(train_X, train_y)\n",
        "\n",
        "# we pass the testing data to the stored algorithm to predict the outcome\n",
        "prediction2 = model2.predict(test_X)\n",
        "print('The accuracy of the Decision Tree Classifier is: ', metrics.accuracy_score(prediction2, test_y)) # we check the accuracy of the algorithm\n",
        "#we pass the predicted output by the model and the actual output"
      ],
      "metadata": {
        "id": "IiQqaqzh0ADG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier # KNN classifier\n",
        "model3 = KNeighborsClassifier()\n",
        "\n",
        "# we train the algorithm with training data and training output\n",
        "model3.fit(train_X, train_y)\n",
        "\n",
        "# we pass the testing data to the stored algorithm to predict the outcome\n",
        "prediction3 = model3.predict(test_X)\n",
        "print('The accuracy of the K-Neighbors Classifier is: ', metrics.accuracy_score(prediction3, test_y)) # we check the accuracy of the algorithm\n",
        "#we pass the predicted output by the model and the actual output"
      ],
      "metadata": {
        "id": "XBjodeAy0F9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8DkCKecoSov"
      },
      "source": [
        "from sklearn import svm # for suport vector machine algorithm\n",
        "#Try all kernals ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’\n",
        "model4 = svm.SVC(kernel='poly') # select the svm algorithm\n",
        "\n",
        "# we train the algorithm with training data and training output\n",
        "model4.fit(train_X, train_y)\n",
        "\n",
        "# we pass the testing data to the stored algorithm to predict the outcome\n",
        "prediction4 = model4.predict(test_X)\n",
        "print('The accuracy of the SVM is: ', metrics.accuracy_score(prediction4, test_y)) # we check the accuracy of the algorithm\n",
        "#we pass the predicted output by the model and the actual output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:**\n",
        "1. Classify penguin species using standard machine learning models. (https://www.kaggle.com/datasets/parulpandey/palmer-archipelago-antarctica-penguin-data)\n",
        "2. Diagnosis Breast Cancer using machine learning techniques. (https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data)"
      ],
      "metadata": {
        "id": "gw0L_tg-2rh5"
      }
    }
  ]
}